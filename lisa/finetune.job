#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=T5-FT_fr
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=6
#SBATCH --time=48:00:00
#SBATCH --mem=100000M
#SBATCH --output=lisa/outputs/dl4nlp_finetune_%A.out

module purge
module load 2021
module load Anaconda3/2021.05

source activate dl4nlp

python -u finetuning/finetune.py --language_name French --code fr --splits 100000 200000 1000000 --num_epochs 40 --batch_size 64 
