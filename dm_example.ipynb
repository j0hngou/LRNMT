{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1c2305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration din0s--ccmatrix_en-ro-b5eb1c3b243f258f\n",
      "Reusing dataset parquet (/home/angelos/.cache/huggingface/datasets/din0s___parquet/din0s--ccmatrix_en-ro-b5eb1c3b243f258f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011285a6f585471a80a6519d24f18c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/angelos/.cache/huggingface/datasets/din0s___parquet/din0s--ccmatrix_en-ro-b5eb1c3b243f258f/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-e04cb05df3d5e9e2.arrow\n",
      "Using custom data configuration j0hngou--ccmatrix_en-fr-c75b778ef0fed3ea\n",
      "Reusing dataset parquet (/home/angelos/.cache/huggingface/datasets/j0hngou___parquet/j0hngou--ccmatrix_en-fr-c75b778ef0fed3ea/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899cd4b774194694a7205533f2b82f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/angelos/.cache/huggingface/datasets/j0hngou___parquet/j0hngou--ccmatrix_en-fr-c75b778ef0fed3ea/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0574ddf6b3bda371.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'en-ro': {'source': tensor([[13959,  1566,    12,  3871,    29,    10,    12,   627,  3823, 14743,\n",
       "               5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "  'target': tensor([[  325,     3,  7741,  3630,   627, 28738,    23, 22281,    35,    15,\n",
       "               1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0]]),\n",
       "  'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])},\n",
       " 'en-fr': {'source': tensor([[13959,  1566,    12,  2379,    10,   101,    43,     3,     9,  1696,\n",
       "              16,   286,     6,    11,    27,    31,   195,   428,    82,   182,\n",
       "             200,   269,    95,   552,     8,   414,     5,     1,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0],\n",
       "          [13959,  1566,    12,  2379,    10,  1072,    27,     3,  1544,     3,\n",
       "            4339,    51,    58,     1,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0],\n",
       "          [13959,  1566,    12,  2379,    10,   366,     6,    44, 10158,  1626,\n",
       "            1050,   603,     6,     3,     9,     3,  2866,    13,     3,  1536,\n",
       "               9,     7,  3728, 12582,   764,    12,   124,     7,     7,     8,\n",
       "            1717,    63, 29339,    13,   160, 10838,     6,     8,   296,  4771,\n",
       "            1410,  1239,     1],\n",
       "          [13959,  1566,    12,  2379,    10,   363,    25,   164,    59,    36,\n",
       "            3324,    28,   713,     6,    19,    24,  1442, 13634,     7,    33,\n",
       "            1364,    30,     8,     3,   122,   120,   565,  3113,  5538,     3,\n",
       "             104,   626,    21,   273,   113,   174,    12,  3393,  2656,  1425,\n",
       "               5,     1,     0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]),\n",
       "  'target': tensor([[  673,  2228,  7056,     3, 22263,   260,    73, 11440,     3,    15,\n",
       "              17,   528,  8132,     9,    23,    90,  5476,    20,  5387,  1398,\n",
       "            4007,    31,    85,   520,  9327,     5,     1,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0],\n",
       "          [26858,    18,   106,     3,     9,  2165,    49,   146,     3,  4339,\n",
       "             526,     3,    58,     1,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0],\n",
       "          [  673, 14976,     6,     3,    85, 10158,  1626,  1050,   603,     6,\n",
       "              73, 19945,    20,     3,     7,     9,     3,  9680,  2060,     3,\n",
       "            1536,     9, 10692,    15,   259,     3,  1926,    76,   124,     7,\n",
       "               7,    49,    90,   851,  9965,  6761,    20,  1394,  1916,   144,\n",
       "               7,     6,    90,  2921,     3,     9, 19950,    50,  1410,  4841,\n",
       "               1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0],\n",
       "          [ 3307,   197,   238,   327,     3,    29,    15,     3,     7,  3618,\n",
       "            1351,    18,  2680,   330,     6,   197, 14409,     6,     3,    75,\n",
       "              22,   222,   238,   110,  4514,     9,  1496, 22423,     7,    30,\n",
       "              17,    73, 15662,     3, 19082,     3,   122,   120,    75, 15845,\n",
       "             835,     3,   104, 12981,   171,   110,  3787,   285,    30,    17,\n",
       "            6350,    20,   244,   162,  7613,  1089, 17035,    20, 20700,     5,\n",
       "               1]]),\n",
       "  'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "          [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datamodules.mt_distillation_datamodule import MTDistillationDatamodule\n",
    "\n",
    "dm = MTDistillationDatamodule(batch_size=5)\n",
    "dm.setup()\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f81e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 43])\n",
      "torch.Size([1, 43])\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"en-fr\"][\"source\"].shape)\n",
    "print(batch[\"en-ro\"][\"source\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5ad7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39d526b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-21.9249,  -8.9075,  -9.3580,  ..., -46.9724, -47.1455, -47.0554],\n",
       "         [-21.4823, -10.0551,  -4.1233,  ..., -42.9394, -43.0076, -42.9269],\n",
       "         [-23.4109,  -9.6241, -13.6325,  ..., -47.0220, -47.0796, -47.0454],\n",
       "         ...,\n",
       "         [-10.6927,  -4.4714,  -9.4419,  ..., -39.3290, -39.4041, -39.4781],\n",
       "         [-10.8941,  -4.4819,  -9.5339,  ..., -39.4958, -39.5699, -39.6404],\n",
       "         [-10.9117,  -4.4439,  -9.5682,  ..., -39.4095, -39.4821, -39.5508]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids=batch[\"en-ro\"][\"source\"], \n",
    "      attention_mask=batch[\"en-ro\"][\"attention_mask\"], \n",
    "      decoder_input_ids=batch[\"en-ro\"][\"target\"],     \n",
    "      decoder_attention_mask=batch[\"en-ro\"][\"decoder_attention_mask\"]\n",
    "     ).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e65907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
