{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Embedding' from 'transformers.models.t5.modeling_t5' (/home/john/anaconda3/envs/dl4nlp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/john/Desktop/MSc AI/DL4NLP/Project/distiller/distiller_example.ipynb Cell 1\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/john/Desktop/MSc%20AI/DL4NLP/Project/distiller/distiller_example.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/john/Desktop/MSc%20AI/DL4NLP/Project/distiller/distiller_example.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/john/Desktop/MSc%20AI/DL4NLP/Project/distiller/distiller_example.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mt5\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodeling_t5\u001b[39;00m \u001b[39mimport\u001b[39;00m T5Stack, T5ForConditionalGeneration, Embedding\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/john/Desktop/MSc%20AI/DL4NLP/Project/distiller/distiller_example.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model_checkpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mt5-small\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Embedding' from 'transformers.models.t5.modeling_t5' (/home/john/anaconda3/envs/dl4nlp/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py)"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import argparse\n",
    "import wandb\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch.nn import Module\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from transformers import PretrainedConfig\n",
    "from transformers.models.t5.modeling_t5 import T5Stack, T5ForConditionalGeneration\n",
    "\n",
    "model_checkpoint = \"t5-small\"\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0- T5ForConditionalGeneration\n",
      "   1- Embedding\n",
      "   1- T5Stack\n",
      "      2- Embedding\n",
      "      2- ModuleList\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Embedding\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "      2- T5LayerNorm\n",
      "      2- Dropout\n",
      "   1- T5Stack\n",
      "      2- Embedding\n",
      "      2- ModuleList\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Embedding\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "         3- T5Block\n",
      "            4- ModuleList\n",
      "               5- T5LayerSelfAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerCrossAttention\n",
      "                  6- T5Attention\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "               5- T5LayerFF\n",
      "                  6- T5DenseActDense\n",
      "                     7- Linear\n",
      "                     7- Linear\n",
      "                     7- Dropout\n",
      "                     7- ReLU\n",
      "                  6- T5LayerNorm\n",
      "                  6- Dropout\n",
      "      2- T5LayerNorm\n",
      "      2- Dropout\n",
      "   1- Linear\n"
     ]
    }
   ],
   "source": [
    "def visualize_children(\n",
    "    object,\n",
    "    level : int = 0,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Prints the children of (object) and their children too, if there are any.\n",
    "    Uses the current depth (level) to print things in a ordonnate manner.\n",
    "    \"\"\"\n",
    "    print(f\"{'   ' * level}{level}- {type(object).__name__}\")\n",
    "    try:\n",
    "        for child in object.children():\n",
    "            visualize_children(child, level + 1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "visualize_children(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_student_model(teacher: Module,\n",
    "                         n: int):\n",
    "    \"\"\"Create a student model from a teacher model.\n",
    "\n",
    "    Args:\n",
    "        teacher: The teacher model.\n",
    "        n: The fraction of the teacher model to keep.\n",
    "\n",
    "    Returns:\n",
    "        A student model.\n",
    "    \"\"\"\n",
    "    config = teacher.config.to_dict()\n",
    "    config['num_layers'] //= n\n",
    "    config['num_decoder_layers'] //= n\n",
    "    config = PretrainedConfig.from_dict(config)\n",
    "    student_model = type(teacher)(config)\n",
    "    student = student_model\n",
    "    student.n = n\n",
    "    init_student_weights(teacher, student)\n",
    "    return student\n",
    "\n",
    "def init_student_weights(teacher: Module,\n",
    "                         student: Module):\n",
    "    \"\"\"Initialize the weights of a student model.\n",
    "\n",
    "    Args:\n",
    "        student: The student model.\n",
    "        teacher: The teacher model.\n",
    "    \"\"\"\n",
    "    student.shared.weight.data = teacher.shared.weight.data\n",
    "    # Encoder\n",
    "    for i in range(student.config.num_layers):\n",
    "        student.encoder.block[i].load_state_dict(teacher.encoder.block[i * student.n].state_dict())\n",
    "    # Decoder\n",
    "    for i in range(student.config.num_decoder_layers):\n",
    "        student.decoder.block[i].load_state_dict(teacher.decoder.block[i * student.n].state_dict())\n",
    "    # Copy first embedding "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('dl4nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58d13f2f10dccb1fc6980cbdb204b9a9907a6ae2fdecbf08799c872bf73330f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
